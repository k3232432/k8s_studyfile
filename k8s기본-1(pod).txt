Pod
쿠버네티스에서 관리하는 가장 작은 배포 단위
※쿠버네티스 vs 도커 
도커는 컨테이너를 만듬 , 쿠버네티스는 pod를 만듬(1개의 pod안에는 여러개의 컨테이너 포함)

빠르게 pod만드는 방법
kebctl run 명령어
kubectl run echo --image ghcr.io/subicura/echo:v1
#echo라는 이름의 pod가 잘 생성되었는지 확인
kubectl get pod
정상적으로 컨테이너가 생성되면 running상태로 바뀌며, 오류가 있다면 에러상태를 표시합니다.
# 단일 Pod 상세 확인
kubectl describe pod/echo

상세 확인을 하였다면 events 부분에서 많은 정보를 알 수 잇음.

Pod 생성 분석[(pod-1)이미지 참고]
pod는 minikube클러스터 안에 pod가 있고, pod 내부에 컨테이너가 존재함.
kubectl run을 실행하고 pod가 생성되는 과정은 아래와 같음.
1. Scheduler는 API서버를 감시하면서 할당되지 않은unassigned Pod이 있는지 체크
2. Scheduler는 할당되지 않은 Pod을 감지하고 적절한 노드node에 할당 (minikube는 단일 노드)
3. 노드에 설치된 kubelet은 자신의 노드에 할당된 Pod이 있는지 체크
4. kubelet은 Scheduler에 의해 자신에게 할당된 Pod의 정보를 확인하고 컨테이너 생성
5. kubelet은 자신에게 할당된 Pod의 상태를 API 서버에 전달

이점으로 알수 있는 부분은 노드가 수십,수백개가 되어도 Scheuler만 열심히 일하면 문제가 없는 구조

kubectl delete pod/echo

YAML로 설정(Spec)작성하기
kubectl run명령어로 다양한 설정을 하게되면 복잡해지며, 관리하기 어려워 진다.
원하는 리소스를 YAML파일로 작성하면 복잡한 내용을 표현하기 좋고 변경된 내용을 버전관리 할 수 있음.
echo포드를 만들었던것을 YAML파일로 정의 하면 아래와 같음.
========echo-pod.yml==============
apiVersion: v1
kind: Pod
metadata:
  name: echo
  labels:
    app: echo
spec:
  containers:
    - name: app
      image: ghcr.io/subicura/echo:v1
=================================

기존에 run명령어로 생성할 때와의 차이점은 label이 추가되었다는 점이다.
쿠버네티스는 리소스를 관리할 때 name과 label을 이용합니다.
필수요소.
정의 	설명		예시
version	오브젝트 버전	v1, app/v1, networking.k8s.io/v1, ...
kind	종류		Pod, ReplicaSet, Deployment, Service, ...
metadata	메타데이터	name과 label, annotation(주석)으로 구성
spec	상세명세		리소스 종류마다 다름

version,kind,metadata,spec는 리소스를 정의할 때 반드시 필요한 요소이다.
※쿠버네티스의 버전에 따라 지원하는 리소스의 버전이 다를 수 있음.
# Pod 생성
kubectl apply -f echo-pod.yml
# Pod 목록 조회
kubectl get pod
# Pod 로그 확인
kubectl logs echo
kubectl logs -f echo
# Pod 컨테이너 접속
kubectl exec -it echo -- sh
# ls
# ps
# exit
# Pod 제거
kubectl delete -f echo-pod.yml

컨테이너 상태 모니터링[(pod-2.png)사진 참조]
컨테이너 생성과 실제 서비스 준비는 약간의 차이가 있음.
서버를 실행하면 바로 접속이 안되며, 조금의 초기화 시간이 필요한데
 실제로 접속이 가능할 때 서비스가 준비되었다고 말할 수 있음.

livenessProbe
컨테이너가 정상적으로 동작하는지 체크하고 정상적으로 동작하지 않는다면 컨테이너를 재시작해 문제를 해결함.
'정상' 이라는 것은 여러가지 방식으로 체크 할 수 있는데 여기서 http get요청을 보내 확인하는 방법을 사용함.
==========echo-lp.yml================
apiVersion: v1
kind: Pod
metadata:
  name: echo-lp
  labels:
    app: echo
spec:
  containers:
    - name: app
      image: ghcr.io/subicura/echo:v1
      livenessProbe:
        httpGet:
          path: /not/exist
          port: 8080
        initialDelaySeconds: 5
        timeoutSeconds: 2 # Default 1
        periodSeconds: 5 # Defaults 10
        failureThreshold: 1 # Defaults 3
=================================
일부러 존재하지 않는 path(/not/exist)와 port(8080)을 추가했음
#echo-lp.yml을 이용하여 echo pod생성
kubectl apply -f echo-lp.yml 
#pod echo의 상태를 확인 하면 CrashLoopBackOff상태가 된걸 확인
kubectl get pod/echo
#pod의 상세 상태 확인
kubectl describe pod/echo

readinessProbe
컨테이너가 준비되었는지 체크 및 정상적으로 준비되지 않았다면 pod으로 돌아오는 요청 제외
livenessProbe와 차이점은 문제가 있어도 pod를 재시작하지 않고 요청만 제외한다는 점.
==========echo-rp.yml===============
apiVersion: v1
kind: Pod
metadata:
  name: echo-rp
  labels:
    app: echo
spec:
  containers:
    - name: app
      image: ghcr.io/subicura/echo:v1
      readinessProbe:
        httpGet:
          path: /not/exist
          port: 8080
        initialDelaySeconds: 5
        timeoutSeconds: 2 # Default 1
        periodSeconds: 5 # Defaults 10
        failureThreshold: 1 # Defaults 3
==================================
#echo-rp 포드 실행
kubectl apply -f echo-rp.yml
#echo-rp.yml 상태 확인
kubectl get pod/echo-rp.yml
#echo-rp.yml 상세상태 확인
kubectl describe pod/echo-rp
Ready 상태가 0/1인것을 확인 할 수 있음.

livenessProbe + readinessProbe
보통 livenessProbe 와 readinessProbe를 같이 적용함.
상세한 설정은 애플리케이션 환경에 따라 적절하게 조정함.
================echo-pod-health.yml==========
apiVersion: v1
kind: Pod
metadata:
  name: echo-health
  labels:
    app: echo
spec:
  containers:
    - name: app
      image: ghcr.io/subicura/echo:v1
      livenessProbe:
        httpGet:
          path: /
          port: 3000
      readinessProbe:
        httpGet:
          path: /
          port: 3000
===========================================
#echo-pod-health.yml 포드 생성
kubectl apply -f echo-pod-health.yml
#pod의 상태 확인
kubectl get pod/echo-health
#pod의 상세 상태 확인
kubectl describe pod/echo-health
#Tset한 모든 pod 삭제
kubectl delete pod --all

다중 컨테이너
대부분 1pod = 1 컨테이너 지만, 여러개의 컨테이너를 가진 경우도 꽤 흔함.
하나의pod에 속한 컨테이너는 서로 네트워크를 localhost로 공유하고 동일한 디렉토리를 공유할 수 있음.
========counter-pod-redis.yml==============
apiVersion: v1
kind: Pod
metadata:
  name: counter
  labels:
    app: counter
spec:
  containers:
    - name: app
      image: ghcr.io/subicura/counter:latest
      env:
        - name: REDIS_HOST
          value: "localhost"
    - name: db
      image: redis
==================================
#counter-pod-redis.yml을 실행합니다.
kubectl apply -f counter-pod-redis.yml 
# 실행된 pod의 상태를 확인합니다.
kubectl get pod (특정 포드 선택시 kubectl get pod/counter)
# 실행된 pod의 상세 상태를 확인합니다.
kubectl describe pod (특정 포드 선택시 kubectl decribe pod/counter)

위의 yml파일은 요청횟수를 redis에 저장하는 간단한 웹 애플리케이션을 다중 컨테이너로 생성한 것.
※이번 yml파일에서는 환경변수(env) 정의가 추가됨. env는 name 과 value를 별도로 정의함.
다중 컨테이너를 포함한 pod는 다음과 같음.[(pod-3.PNG)파일 참조]
같은 Pod에 컨테이너가 생성되었기 때문에 counter앱은 redis를 localhost로 접근 가능하다.
컨테이너에 적접 접속해서 test진행

# Pod 생성
kubectl apply -f counter-pod-redis.yml

# Pod 목록 조회
kubectl get pod

# Pod 로그 확인
kubectl logs counter # 오류 발생 (컨테이너 지정 필요)
kubectl logs counter app
kubectl logs counter db

# Pod의 app컨테이너 접속
kubectl exec -it counter -c app -- sh
# apk add curl busybox-extras # install curl, telnet
# curl localhost:3000
# curl localhost:3000
# telnet localhost 6379
  dbsize
  KEYS *
  GET count
  quit

# Pod 제거
kubectl delete -f counter-pod-redis.yml
멀티 컨테이너를 이용해 로그수집용 컨테이너를 같은 pod안에 넣는다던지, 서버가 실행되기전 데이터베이스를
마이그레이션하는 초기화 컨테이너를 만들 수 있음.

pod는 단독으로 사용하는 경우는 거의없음, pod가 컨테이너를 관리하듯 다른 컨트롤러가 pod를 관리

실습 1.
다음 조건을 만족하는 Pod를 만드시오.
키		값
pod이름		mongodb
podlabel		app: mongo
container이름	mongodb
container이미지	mongo:4

실습2
다음 조건을 만족하는 pod를 만드시오.
키		값
pod이름		mysql
podlabel		app: mysql
container이름	mysql
container이미지	mysql:5.7
container환경변수	MYSQL_ROOT_PASSWORD: 123456


